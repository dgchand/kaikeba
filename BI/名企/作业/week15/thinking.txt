-------------------------------
Thinking1	
逻辑回归的假设条件是怎样的？			
能简要说明逻辑回归的假设条件（10points）

假设条件1:数据服从伯努利分布，为离散型概率分布，以一定概率成功，成功时取值为1，失败时取值为0.
条件2:正类（成功类）的概率有sigmoid函数计算。
其余假设条件包括误差项是独立等



-------------------------------
Thinking2	
逻辑回归的损失函数是怎样的？			
能简要说明逻辑回归的损失函数（10points）

损失函数为
cost(h(x),y) = -log(h(x)), if y=1
		-log(1-h(x)), if y=0
其中h(x)预测函数， P(y=1|x,sita) = h(x) = 1-P(y=0|x,sita)


-------------------------------
Thinking3	
逻辑回归如何进行分类？			
能简要说明逻辑回归是如何进行分类的（10points）

构造预测函数后计算损失函数，使用最大似然函数求的参数的值。代入预测的自变量后计算其正类概率。
设定一个阈值，判断正类概率是否大于该阈值，一般阈值是0.5，所以只用判断正类概率是否大于0.5即可



-------------------------------
Thinking4	
为什么在训练中需要将高度相关的特征去掉？			
简要说明为什么要去掉相关度高的特征（10points）

去掉相关度高的特征的话可解释性更好，同时可以提高训练的速度，特征多了，会增大训练的时间
