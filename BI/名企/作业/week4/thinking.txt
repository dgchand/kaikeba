-----------------------
Thinking1	奇异值分解SVD的原理是怎样的，都有哪些应用场景			
"1、能简单说明奇异值分解的原理（5points）
2、举例说明两个以上的使用场景（5points)
"

当矩阵A是对称方阵时，A可分解为三个矩阵，依次为以A的特征向量为列向量的矩阵、以特征向量的特征值的对焦矩阵以
及第一个矩阵的转置。
当A不是对称方阵时，用A乘其转置以及用其转置乘A本身，可得到两个对阵方阵，对其分别分解，取分解的首个矩阵，可
得到P、Q。
从而得到A的奇异值分解。

可用于推荐系统，则其中P左奇异矩阵为User矩阵，Q右奇异矩阵为Item矩阵。还可以用于图像压缩，
用少量的特征值、向量矩阵保存主要图像信息，通过小于A的维度m、n的k来对矩阵降维。





-----------------------
Thinking2	funkSVD, BiasSVD，SVD++算法之间的区别是怎样的			
"1、能简述3种算法之间的差异（10points)
"

FunkSVD通过梯度下降法求解User矩阵和item矩阵使得损失函数最小化。基于SVD存在的稀疏问题而只使用两个矩阵相乘。
BiasSVD在FunkSVD的基础上考虑用户和商品偏好部分。
SVD++在BiasSVD基础上考虑隐式反馈，如不具体的评分，点击、浏览等行为。




-----------------------
Thinking3	矩阵分解算法在推荐系统中有哪些应用场景，存在哪些不足			
"1、能说明推荐系统中的典型应用场景（5points）
2、MF在推荐系统中的局限性（5points）"

矩阵分解在推荐系统中，可以将经典的user-item评分问题转化为矩阵分解问题。其中信息量不大的特征值可适当舍去从而
达到矩阵降维的效果。但是会要求矩阵时稠密的。大量的缺失值会导致运算量大，同时填充方式的粗暴会引起大噪音。
MF还存在不足，只考虑了user和item特征，对于其他特征的利用，如最优化评分误差、用户/商品偏好以及隐式反馈，
我们需要使用新的工具。





-----------------------
Thinking4	
假设一个小说网站，有N部小说，每部小说都有摘要描述。如何针对该网站制定基于内容的推荐系统，即用户看了某部
小说后，推荐其他相关的小说。原理和步骤是怎样的			
能简要说明基于内容进行推荐的步骤及原理（10points)

1.对小说的摘要描述进行特征提取。可以选择N-Gram提取N个连续子的集合或者TF-IDF按照最小最大提取关键词。
2.计算小说之间的相似度矩阵，使用余弦相似度进行计算。
3.对于指定的小说（某个用户之前看过的小说），选择相似度最大的TopK个小说进行输出，生成推荐列表。





-----------------------
Thinking5	Word2Vec的应用场景有哪些			
能说明在NLP和推荐系统中的应用场景（10points）

Word2Vec通过Embedding把原先词所在的空间映射到一个新的空间去，使得语义上相似的单词在该空间中距离相近。
Word2Vec实际上是一个查找表，有Skip-gram以及CBOW两种模式。
在推荐系统中，将语句中的词转换为固定大小的向量表达后，训练后可用于计算两个商品的相似度。如在商品推荐中，
商品即单词，用户对商品的行为顺序就是语句、文章。






