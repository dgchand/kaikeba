----------------
Thinking1	
在CTR点击率预估中，使用GBDT+LR的原理是什么？			
能简要说明GBDT和LR在CTR预估中的作用（10point）

原理是先试用GBDT进行新特征的构造，之后在新特征的基础上使用LR完成对目标的预估。其中BGBDT是一种非线性的基于集成学习boosting的迭代算法，其得到的特征、
特征组合具有区分性，在特征选择上不亚于人工经验的处理方式。
GBDT+LR相比单纯的LR和GBDT，在效果上、loss上能够有明显的提升作用。


----------------
Thinking2	
Wide & Deep的模型结构是怎样的，为什么能通过具备记忆和泛化能力（memorization and generalization）			
"1、能简要说明Wide&Deep的模型（5point）
2、如何具备记忆和泛化能力（5point）
"

Wide推荐时系统通过获得用户的购物日志数据，然后通过OneHot编码转换为离散特征。其可解释强，不足是特征组合需要人为操作。Wide是线性模型，
输入特征可以是连续特征也可以是稀疏的离散特征。离散特镇高通过交叉组成更高纬的离散特征。
Deep推荐通过深度学习出一些向量，其可解释性弱。使用连续的特征，特征首先转化为低纬稠密向量，作为第一个隐藏层的的输入，解决维度爆炸的问题。
Wide&Deep模型不论在线下还是线上相比于单独的wide模型和单独的deep模型，效果都有明显的提升。

两个模型的融合能够通过emsemble的方法，用两个模型分别对全量数据进行预测，然后根据权重组合最终的预测结果；或者通过joint training的方法，
Wide和deep的特征合一，构成一个模型进行预测。使得模型同时具备记忆和泛化的能力





----------------
Thinking3	
在CTR预估中，使用FM与DNN结合的方式，有哪些结合的方式，代表模型有哪些？			
"1、能说出哪两种FM和DNN的组合方式（5points）
2、能说出FM和DNN的组合出的算法（5points）"

FM和DNN的组合方式有 DeepFM，将Wide&Deep中的Wide提换乘FM，并行结构，FM和DNN分开计算；以及NFM，对embedding直接采用对位相乘作为交叉
特征，最后concatenate 线性部分和deep部分，是串行结构，将FM的结果作为DNN的输入。



----------------
Thinking4	
GBDT和随机森林都是基于树的算法，它们有什么区别？			
能简要说明这两种基于树的算法的不同（10points）

GBDT和RF都是集成学习方法。GBDT属于boosting，通过将弱学习器提升为强学习器的集成方法来提高预测精度。每一轮迭代，GBDT将上一次的残差作为新的目标学习，
进而不断迭代学习。
RF属于bagging的集成方法，通过自主采样的方法生成众多并行式的分类器，通过少数服从多数的原则来确定最终的结果。RF使用多个并行的DT集成少数服从多数的学习器。




----------------
Thinking5	
item流行度在推荐系统中有怎样的应用			
"1、冷启动中的使用（10points)
2、协同过滤中的TopN推荐（10points）
3、其他使用（+5points)"

流行度的衡量有很多度量方式，有粗有细；如一段时间内的总数、相对值、可能性。影响流行度的因素有时间因素、空间因素、社会信息因素、个性与群体的区别等。
流行度能解决冷启动的问题，根据流行度来推荐商品的算法，即根据什么内容吸引用户来给用户推荐内容。当用户行为信息不足时，采用非个性化推荐。
TopN推荐属于基于流行度的推荐是围绕流行度计算产生的推荐模型，将榜单的热度内容推荐给用户。
流行度还能用于电商网站如唯品会特卖打造爆款以及婚恋网站使用户活跃等场景。


















